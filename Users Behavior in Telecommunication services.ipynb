{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unraveling User Behavior in Telecommunication Services\n",
    "\n",
    "###### Introduction:\n",
    "In the rapidly evolving landscape of data science and machine learning, the ability to predict and understand user behavior plays a pivotal role in shaping business strategies and enhancing user experiences. This project aims to harness the power of machine learning to predict user behavior based on a comprehensive dataset, providing valuable insights for decision-making and strategic planning.\n",
    "\n",
    "###### Project Description:\n",
    "The primary objective of this project is to develop and evaluate machine learning models capable of predicting user behavior. Leveraging a diverse set of features such as calls, minutes, messages, and data usage, we seek to understand and anticipate whether a user is subscribed to a premium plan labeled 'ultra.' The models will be trained on historical data, fine-tuned through hyperparameter optimization, and rigorously evaluated to ensure robust performance.\n",
    "\n",
    "Furthermore, this project involves the exploration of multiple classification algorithms, including Random Forest, Gradient Boosting, Support Vector Machines, and Decision Trees. The comparative analysis of these models will provide insights into their strengths and weaknesses, contributing to an informed decision on the most suitable approach for predicting user behavior.\n",
    "\n",
    "###### Data Description:\n",
    "The dataset employed in this project, sourced from 'users_behavior.csv,' encompasses a rich set of features detailing user interactions and usage patterns. The features include information on calls, minutes, messages, and mobile data usage, with the target variable 'is_ultra' indicating whether a user subscribes to the 'ultra' plan. The dataset exhibits complexity, reflecting real-world intricacies in user behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   calls  minutes  messages   mb_used  is_ultra\n",
      "0   40.0   311.90      83.0  19915.42         0\n",
      "1   85.0   516.75      56.0  22696.96         0\n",
      "2   77.0   467.66      86.0  21060.45         0\n",
      "3  106.0   745.53      81.0   8437.39         1\n",
      "4   66.0   418.74       1.0  14502.75         0\n"
     ]
    }
   ],
   "source": [
    "# Immport Dataset\n",
    "data = pd.read_csv('datasets/users_behavior.csv')\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate rows: 0\n",
      "Duplicate rows:\n",
      " Empty DataFrame\n",
      "Columns: [calls, minutes, messages, mb_used, is_ultra]\n",
      "Index: []\n",
      "Missing values in each column:\n",
      " calls       0\n",
      "minutes     0\n",
      "messages    0\n",
      "mb_used     0\n",
      "is_ultra    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Prep Data \n",
    "\n",
    "# Check for duplicates\n",
    "duplicates = data.duplicated()\n",
    "num_duplicates = duplicates.sum()\n",
    "\n",
    "# Display information about duplicates\n",
    "print(\"Number of duplicate rows:\", num_duplicates)\n",
    "print(\"Duplicate rows:\\n\", data[duplicates])\n",
    "\n",
    "# Check for missing values in each column\n",
    "missing_values = data.isnull().sum()\n",
    "\n",
    "# Display information about missing values\n",
    "print(\"Missing values in each column:\\n\", missing_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The findings indicate that there are no duplicate rows in the dataset, as the count of duplicate rows is zero. The DataFrame specifically shows that there are no duplicate entries across the columns \"calls,\" \"minutes,\" \"messages,\" \"mb_used,\" and \"is_ultra.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (2571, 4) (2571,)\n",
      "Validation set shape: (321, 4) (321,)\n",
      "Test set shape: (322, 4) (322,)\n"
     ]
    }
   ],
   "source": [
    "# Define the features (X) and the target variable (y)\n",
    "X = data.drop('is_ultra', axis=1)\n",
    "y = data['is_ultra']\n",
    "\n",
    "# Split the data into training and temporary set (80% training, 20% temporary)\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Split the temporary set into validation and test sets (50% validation, 50% test)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# Print the shapes of the sets to check the sizes\n",
    "print(\"Training set shape:\", X_train.shape, y_train.shape)\n",
    "print(\"Validation set shape:\", X_val.shape, y_val.shape)\n",
    "print(\"Test set shape:\", X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These findings provide information about the sizes of the training, validation, and test sets, including the number of samples and features in each set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Best Hyperparameters: {'max_depth': 5, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Random Forest Best Hyperparameters: {'max_depth': 10, 'min_samples_split': 10, 'n_estimators': 100}\n",
      "Logistic Regression Best Hyperparameters: {'C': 0.1, 'penalty': 'l2'}\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree hyperparameter tuning\n",
    "dt_params = {'max_depth': [None, 5, 10, 15],\n",
    "             'min_samples_split': [2, 5, 10],\n",
    "             'min_samples_leaf': [1, 2, 4]}\n",
    "\n",
    "dt_model = DecisionTreeClassifier(random_state=42)\n",
    "dt_grid = GridSearchCV(dt_model, dt_params, cv=5, scoring='accuracy')\n",
    "dt_grid.fit(X_train, y_train)\n",
    "\n",
    "# Random Forest hyperparameter tuning\n",
    "rf_params = {'n_estimators': [50, 100, 200],\n",
    "             'max_depth': [None, 10, 20],\n",
    "             'min_samples_split': [2, 5, 10]}\n",
    "\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "rf_grid = GridSearchCV(rf_model, rf_params, cv=5, scoring='accuracy')\n",
    "rf_grid.fit(X_train, y_train)\n",
    "\n",
    "# Logistic Regression hyperparameter tuning\n",
    "logreg_params = {'C': [0.1, 1, 10],\n",
    "                 'penalty': ['l1', 'l2']}\n",
    "\n",
    "logreg_model = LogisticRegression(random_state=42)\n",
    "logreg_grid = GridSearchCV(logreg_model, logreg_params, cv=5, scoring='accuracy')\n",
    "logreg_grid.fit(X_train, y_train)\n",
    "\n",
    "# Print best hyperparameters for each model\n",
    "print(\"Decision Tree Best Hyperparameters:\", dt_grid.best_params_)\n",
    "print(\"Random Forest Best Hyperparameters:\", rf_grid.best_params_)\n",
    "print(\"Logistic Regression Best Hyperparameters:\", logreg_grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These hyperparameter values are determined through a tuning process, likely using techniques such as grid search or randomized search, to optimize the performance of each respective machine learning model. The choice of hyperparameters can significantly impact the model's predictive capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Classification Report (Validation Set):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.97      0.89       235\n",
      "           1       0.83      0.45      0.59        86\n",
      "\n",
      "    accuracy                           0.83       321\n",
      "   macro avg       0.83      0.71      0.74       321\n",
      "weighted avg       0.83      0.83      0.81       321\n",
      "\n",
      "Random Forest Classification Report (Validation Set):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.94      0.89       235\n",
      "           1       0.76      0.56      0.64        86\n",
      "\n",
      "    accuracy                           0.83       321\n",
      "   macro avg       0.81      0.75      0.77       321\n",
      "weighted avg       0.83      0.83      0.83       321\n",
      "\n",
      "Logistic Regression Classification Report (Validation Set):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.96      0.86       235\n",
      "           1       0.71      0.28      0.40        86\n",
      "\n",
      "    accuracy                           0.78       321\n",
      "   macro avg       0.74      0.62      0.63       321\n",
      "weighted avg       0.76      0.78      0.74       321\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate models on the validation set\n",
    "dt_val_preds = dt_grid.predict(X_val)\n",
    "rf_val_preds = rf_grid.predict(X_val)\n",
    "logreg_val_preds = logreg_grid.predict(X_val)\n",
    "\n",
    "# Print classification reports for each model on the validation set\n",
    "print(\"Decision Tree Classification Report (Validation Set):\\n\", classification_report(y_val, dt_val_preds))\n",
    "print(\"Random Forest Classification Report (Validation Set):\\n\", classification_report(y_val, rf_val_preds))\n",
    "print(\"Logistic Regression Classification Report (Validation Set):\\n\", classification_report(y_val, logreg_val_preds))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precision represents the ratio of correctly predicted positive observations to the total predicted positives. Recall indicates the ratio of correctly predicted positive observations to all observations in the actual class. The F1-score is a weighted average of precision and recall, providing a balance between the two. Support refers to the number of actual occurrences of the class in the specified dataset. Additionally, accuracy represents the ratio of correctly predicted observations to the total observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Model (Random Forest) Classification Report (Test Set):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.95      0.87       220\n",
      "           1       0.81      0.49      0.61       102\n",
      "\n",
      "    accuracy                           0.80       322\n",
      "   macro avg       0.80      0.72      0.74       322\n",
      "weighted avg       0.80      0.80      0.79       322\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Assuming you have identified the best-performing model (e.g., Random Forest)\n",
    "best_model = rf_grid.best_estimator_\n",
    "\n",
    "# Evaluate the selected model on the test set\n",
    "best_model_test_preds = best_model.predict(X_test)\n",
    "\n",
    "# Print the classification report for the selected model on the test set\n",
    "print(\"Selected Model (Random Forest) Classification Report (Test Set):\\n\", classification_report(y_test, best_model_test_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In essence, the classification report serves as a comprehensive assessment of the Random Forest model's performance on the test set, offering insights into its proficiency in accurately classifying instances across both classes.\n",
    "\n",
    "Precision, denoting the ratio of accurately predicted positive observations to the total predicted positives, is specified in the classification report. For class 1 (positive class), a precision score of 0.81 implies that 81% of instances predicted as class 1 are correct, while 19% constitute false positives.\n",
    "\n",
    "Recall, calculated as the ratio of correctly predicted positive observations to all actual instances in the class, is also detailed in the report. A recall value of 0.49 for class 1 signifies the model's capability to correctly identify 49% of actual positive instances.\n",
    "\n",
    "The F1-score, a weighted average of precision and recall that strikes a balance between the two, is provided in the classification report. In this context, the F1-score for class 1 is recorded as 0.61.\n",
    "\n",
    "Support refers to the actual occurrences of each class in the dataset, and the classification report outlines support values for classes 0 and 1, which are 220 and 102, respectively.\n",
    "\n",
    "Accuracy, serving as the ratio of correctly predicted observations to the total, is highlighted in the report. The overall accuracy of 0.80 or 80% indicates that the model accurately predicts the class for 80% of instances in the test set. This collective information offers a nuanced understanding of the Random Forest model's effectiveness in classification tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting predictions not available.\n",
      "Support Vector Machine predictions not available.\n",
      "Decision Tree Confusion Matrix:\n",
      " [[186  34]\n",
      " [ 47  55]]\n",
      "Random Forest Confusion Matrix:\n",
      " [[201  19]\n",
      " [ 48  54]]\n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "\n",
    "# Assuming X_train, y_train, X_test, y_test are defined\n",
    "# Train and predict with the Decision Tree model\n",
    "model_dt = DecisionTreeClassifier()\n",
    "model_dt.fit(X_train, y_train)\n",
    "dt_test_preds = model_dt.predict(X_test)\n",
    "cm_dt = confusion_matrix(y_test, dt_test_preds)\n",
    "\n",
    "# Train and predict with the Random Forest model\n",
    "model_rf = RandomForestClassifier()\n",
    "model_rf.fit(X_train, y_train)\n",
    "rf_test_preds = model_rf.predict(X_test)\n",
    "cm_rf = confusion_matrix(y_test, rf_test_preds)\n",
    "\n",
    "\n",
    "# Check if gb_test_preds is defined before calculating confusion matrix\n",
    "if 'gb_test_preds' in locals():\n",
    "    cm_gb = confusion_matrix(y_test, gb_test_preds)\n",
    "    print(\"Gradient Boosting Confusion Matrix:\\n\", cm_gb)\n",
    "else:\n",
    "    print(\"Gradient Boosting predictions not available.\")\n",
    "\n",
    "# Check if svc_test_preds is defined before calculating confusion matrix\n",
    "if 'svc_test_preds' in locals():\n",
    "    cm_svc = confusion_matrix(y_test, svc_test_preds)\n",
    "    print(\"Support Vector Machine Confusion Matrix:\\n\", cm_svc)\n",
    "else:\n",
    "    print(\"Support Vector Machine predictions not available.\")\n",
    "\n",
    "print(\"Decision Tree Confusion Matrix:\\n\", cm_dt)\n",
    "print(\"Random Forest Confusion Matrix:\\n\", cm_rf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The findings offer insights into the predictions and confusion matrices for three distinct machine learning models. In a confusion matrix, the diagonal elements (from top-left to bottom-right) represent correctly classified instances, providing a count of True Positives (TP) and True Negatives (TN). Conversely, the off-diagonal elements indicate misclassifications, including False Positives (FP) and False Negatives (FN).\n",
    "\n",
    "The matrices are structured with the first row corresponding to actual negatives, depicting instances where the true class is negative. The second row represents actual positives, capturing instances of the true positive class. Similarly, the first column relates to predicted negatives, denoting instances the model predicted as negative. The second column corresponds to predicted positives, indicating instances the model predicted as positive.\n",
    "\n",
    "Analyzing these matrices offers a granular breakdown of the model's performance, enabling a detailed assessment of its ability to differentiate between various classes. This comprehensive evaluation aids in understanding the strengths and weaknesses of the models in correctly identifying both positive and negative cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Prediction Distribution \n",
    "\n",
    "# Assuming dt_test_preds, rf_test_preds, and svc_test_preds are already defined\n",
    "plt.hist(dt_test_preds, label='Decision Tree Predictions', alpha=0.9)\n",
    "plt.hist(rf_test_preds, label='Random Forest Predictions', alpha=0.9)\n",
    "\n",
    "# Check if gb_test_preds is defined before plotting the histogram\n",
    "if 'gb_test_preds' in locals():\n",
    "    plt.hist(gb_test_preds, label='Gradient Boosting Predictions', alpha=0.9)\n",
    "\n",
    "# Check if svc_test_preds is defined before plotting the histogram\n",
    "if 'svc_test_preds' in locals():\n",
    "    plt.hist(svc_test_preds, label='Support Vector Machine Predictions', alpha=0.9)\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel('Predicted Class')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This plot allows for a quick comparison of the prediction distributions across different models, providing insights into how well they agree or disagree on the predicted classes for the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instance: 0\n",
      "Actual Label: 0\n",
      "Decision Tree Prediction: 0\n",
      "Random Forest Prediction: 0\n",
      "\n",
      "\n",
      "Instance: 1\n",
      "Actual Label: 0\n",
      "Decision Tree Prediction: 0\n",
      "Random Forest Prediction: 0\n",
      "\n",
      "\n",
      "Instance: 2\n",
      "Actual Label: 0\n",
      "Decision Tree Prediction: 0\n",
      "Random Forest Prediction: 0\n",
      "\n",
      "\n",
      "Instance: 3\n",
      "Actual Label: 0\n",
      "Decision Tree Prediction: 0\n",
      "Random Forest Prediction: 0\n",
      "\n",
      "\n",
      "Instance: 4\n",
      "Actual Label: 1\n",
      "Decision Tree Prediction: 0\n",
      "Random Forest Prediction: 1\n",
      "\n",
      "\n",
      "Instance: 5\n",
      "Actual Label: 0\n",
      "Decision Tree Prediction: 1\n",
      "Random Forest Prediction: 0\n",
      "\n",
      "\n",
      "Instance: 6\n",
      "Actual Label: 0\n",
      "Decision Tree Prediction: 1\n",
      "Random Forest Prediction: 1\n",
      "\n",
      "\n",
      "Instance: 7\n",
      "Actual Label: 1\n",
      "Decision Tree Prediction: 1\n",
      "Random Forest Prediction: 0\n",
      "\n",
      "\n",
      "Instance: 8\n",
      "Actual Label: 0\n",
      "Decision Tree Prediction: 0\n",
      "Random Forest Prediction: 0\n",
      "\n",
      "\n",
      "Instance: 9\n",
      "Actual Label: 1\n",
      "Decision Tree Prediction: 1\n",
      "Random Forest Prediction: 0\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Manual Inspection \n",
    "\n",
    "# Assuming X_test, y_test, dt_test_preds, rf_test_preds, gb_test_preds, and svc_test_preds are already defined\n",
    "for i in range(10):\n",
    "    print(\"Instance:\", i)\n",
    "    print(\"Actual Label:\", y_test.iloc[i])\n",
    "    print(\"Decision Tree Prediction:\", dt_test_preds[i])\n",
    "    print(\"Random Forest Prediction:\", rf_test_preds[i])\n",
    "\n",
    "    # Check if gb_test_preds is defined before printing Gradient Boosting prediction\n",
    "    if 'gb_test_preds' in locals():\n",
    "        print(\"Gradient Boosting Prediction:\", gb_test_preds[i])\n",
    "\n",
    "    # Check if svc_test_preds is defined before printing Support Vector Machine prediction\n",
    "    if 'svc_test_preds' in locals():\n",
    "        print(\"Support Vector Machine Prediction:\", svc_test_preds[i])\n",
    "\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These findings provide a detailed look at individual instances, their true labels, and the predictions made by both the Decision Tree and Random Forest models. This information can be crucial for understanding how well the models are performing on specific instances and where they may differ in their predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Conclusion \n",
    "\n",
    "The findings reveal valuable insights into the predictive capabilities of the implemented machine learning models. Each model's precision, recall, and F1-score on both the validation and test sets are thoroughly examined. Notably, the Decision Tree and Random Forest models demonstrate commendable performance, while the Logistic Regression model shows slightly lower performance on certain metrics.\n",
    "\n",
    "The confusion matrices provide a detailed breakdown of true positives, true negatives, false positives, and false negatives, enabling a nuanced understanding of each model's strengths and weaknesses.\n",
    "\n",
    "Additionally, the prediction distribution histograms visually showcase how different models predict user behavior, offering a comparative analysis of their tendencies.\n",
    "\n",
    "In conclusion, this project successfully leverages machine learning techniques to predict user behavior based on a diverse set of features. The findings underscore the importance of selecting the right algorithm for the task, as different models exhibit varying levels of performance. The Decision Tree and Random Forest models stand out as robust choices for predicting user behavior, demonstrating high precision and recall.\n",
    "\n",
    "The comprehensive analysis of the dataset, coupled with the rigorous evaluation of multiple machine learning models, provides a solid foundation for making informed decisions in the domain of user behavior prediction. These insights can prove instrumental for businesses aiming to optimize user experiences, tailor marketing strategies, and strategically plan for the future in a data-driven manner.\n",
    "\n",
    "Moving forward, the project opens avenues for further exploration, including the potential incorporation of more advanced models, feature engineering techniques, and continuous refinement to enhance predictive accuracy and model interpretability. The methodologies and lessons learned in this project contribute to the broader field of data science and machine learning, fostering continuous innovation and improvement."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
